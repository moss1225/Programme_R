（1）回归诊断
	回归诊断是从研究引起异常的样本的问题，异常样本往往会引起回归模型的不稳定。
	为此，人们提出所谓诊断的问题，主要有以下内容：
1.样品是否符合正太分布假设？
2.是否存在离群值导致模型产生较大误差？
3.线性模型是否合理？
4.误差是否满足独立性、等方差、正态分布等假设条件？
5.是否存在多重共性线性？

（2）正态分布检验
1.p>0.05,正态分布
2.shapiro.test(x$x1)
3.shariro.test(x$x2)

（3）散点图目测检验
P283

(4)残差
在数理统计中，残差是指实际观察值与估计值（拟合值）之间的差。
在回归模型中，测定值与按回归方程预测的值之差。
显然有多少数据，就有多少个残差，残差分析就是通过残差所提供的信息，分析出数据的可靠性、周期性或其它干扰。
侧面检测回归模型的合理性。
***y.res=residuals(lm.sol)#求残差的函数
***shapiro.test(y.res)#检测残差是否符合正态分布
#残差满足正态分布说明模型合理

（5）update()修改模型的函数

（6）残差Q-Q图

（7）多重共线性：所谓多重共线性（Multicollinearity）是指线性回归模型中的解释变量之间由于存在精确相关关系或高度相关关系而使模型估计失真或难以估计准确。
1.在代数里面即线性相关的关系。
2.用kappa衡量多重共线性，<100基本不存在多重共线性。
3.求特征向量，特征限量的值越大，多重共线性的程度越大。

（8）广义线性模型
1.符合logic回归模型的曲线特征
2.广义线性回归模型建模函数：glm()
***fitted.model<-qlm(formula,family=family.generator,data=data.frame)

(9)非线性模型
1.lm.pow<-lm(y~log(x))#对数法
2.lm.pow<-lm(log(y)~x)#指数法
3.lm.pow<-lm(log(y)~log(x))#对数关系
画图：lines(x,exp(fitted(lm.pow)))
#fitted是拟合值，predict是预测值。
#模型是基于给定样本的值建立的，在这些给定样本上做预测就是拟合。在新样本上做预测就是预测。