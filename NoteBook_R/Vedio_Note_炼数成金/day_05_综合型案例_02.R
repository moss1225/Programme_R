#回归与诊断keppa()
#考虑一个有六个回归自变量的线性回归问题，
#原始数据在表中，共十二组数据
#除第一组外，自变量X1,X2,X3...x6满足线性关系
collinear<-data.frame(
		Y=c(10.006, 9.737, 15.087, 8.422, 8.625, 16.289, 
				5.958, 9.313, 12.960, 5.541, 8.756, 10.937),
		X1=rep(c(8, 0, 2, 0), c(3, 3, 3, 3)), 
		X2=rep(c(1, 0, 7, 0), c(3, 3, 3, 3)),
		X3=rep(c(1, 9, 0), c(3, 3, 6)),
		X4=rep(c(1, 0, 1, 10), c(1, 2, 6, 3)),
		X5=c(0.541, 0.130, 2.116, -2.397, -0.046, 0.365,
				1.996, 0.228, 1.38, -0.798, 0.257, 0.440),
		X6=c(-0.099, 0.070, 0.115, 0.252, 0.017, 1.504,
				-0.865, -0.055, 0.502, -0.399, 0.101, 0.432)
)
	#↑输入数据，创建数据集。

XX<-cor(collinear[2:7])
	#↑截取collinear自变量部分
	#↑r软件采用cor()函数计算相关矩阵(相关系数)
	#↑R语言中的函数cor.test()函数进行相关性系数的计算和检验
	#↑r软件采用cov()函数计算相协方差(协方差阵)
	#↑在概率论和统计学中，协方差用于衡量两个变量的总体误差。
	#↑而方差是协方差的一种特殊情况，即当两个变量是相同的情况。

kappa(XX,exact=TRUE)
	#↑输出的kappa的值>1000，说明有严重的多重共线性。

eigen(XX)
	#↑计算特征向量
	#↑$value(min)=0.001106051
	#↑ y=-0.447679719*x1+-0.421140280*x2+-0.541689124*x3+-0.573371872*x4+-0.006052127*x5+-0.002166594*x6
	#↑ x5\x6前的系数近似于0，看做可以x1,x2,x3,x4经过相关线性转换得到
	#↑关系模型预计为y=c1*x1+c2*x2+c3*x3+c4*x4